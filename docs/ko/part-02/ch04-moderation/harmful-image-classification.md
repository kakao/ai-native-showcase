---
layout: default
title: '4.3. 유해 이미지 분류 시스템 구축기'
lang: ko
parent: '제4장. AI 콘텐츠 모더레이션 - 쾌적한 세상을 위한 AI의 노력'
nav_order: 3
permalink: /ko/part-02/ch04-moderation/harmful-image-classification/
author: herschel.alway
---

# 4.3. 유해 이미지 분류 시스템 구축

초기 상황은 명확했습니다. 이미지 콘텐츠의 양은 기하급수적으로 증가하는 반면, 이를 검토하는 인력은 한정적이었습니다. 100% 수동 검토는 운영 피로도를 가중시킬 뿐만 아니라, 사람마다 다른 판단 기준으로 인해 일관성을 유지하기 어려운 구조적 문제를 안고 있었습니다. 때문에 "사람이 직접 검토해야 하는 이미지의 절대적인 수를 줄이자"는 매우 실용적이고 명확한 목표에서 이 프로젝트는 시작되었습니다.

## "사람이 봐야 할 이미지를 어떻게 줄일 것인가?"

유해 이미지 분류 시스템 구축의 목표는 카카오 서비스 내 급증하는 이미지 콘텐츠에 대한 수동 검토의 한계를 극복하고, 운영 효율성과 판단의 일관성을 확보하는 것이었습니다.

## 초기 탐색: CNN 기반 분류의 가능성을 엿보다

본격적인 AI 모델을 개발하기에 앞서, 몇 가지 기본적인 접근법을 테스트하며 문제의 특성을 파악하는 탐색 단계를 거쳤습니다.

가장 먼저 시도한 것은 운영 효율성을 즉각적으로 높일 수 있는 유사 이미지 검색 기술이었습니다. 동일한 유해 이미지가 반복적으로 업로드되는 경우가 많았기에, 이미지의 특징(Feature)을 벡터로 추출하고 Approximate KNN¹ 기술로 유사도를 비교하여 이미 판정된 이미지를 자동으로 걸러내는 시스템을 구축했습니다. 이는 수동 검토 대상을 줄이는 데 실질적인 첫걸음이 되었습니다.

동시에, 새로운 형태의 유해 이미지를 분류하기 위해 CNN(합성곱 신경망)² 기반 모델들의 성능을 테스트했습니다. Inception-ResNet-v2와 같은 당시 공개된 여러 모델들을 활용해보고, 단일 모델의 한계를 극복하기 위해 기본적인 앙상블 기법을 적용해보는 등 다양한 실험을 진행했습니다.

이러한 초기 탐색 과정은 중요한 교훈을 주었습니다. 단순히 공개된 예제를 적용하는 것만으로는 실제 서비스 환경에서 마주하는 속도와 자원 사용량 문제를 해결할 수 없다는 것이었습니다. 정확도는 물론, 실제 서비스 환경에서의 효율성까지 고려한 모델이 필요하다는 결론에 이르렀고, 이는 프로젝트가 다음 단계로 나아가는 계기가 되었습니다.

## 1차 발전: EfficientNet 도입 - 본격적인 AI 모델 개발의 시작

이 시점에서 EfficientNet³을 만나면서 본격적인 AI 모델 개발의 여정을 시작했습니다. EfficientNet의 핵심은 모델의 깊이(depth), 너비(width), 해상도(resolution)를 무작정 키우는 것이 아니라, 정해진 비율에 따라 균형 있게 확장하는 '복합 확장(Compound Scaling)⁴' 방법론에 있습니다.

![출처 : EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks 논문 발췌]({{ site.baseurl }}/images/377cbd7f019900001.png)

하지만, 단 하나의 모델이 모든 상황에 최적일 수는 없었습니다. 서비스의 요구사항에 따라 정확도와 속도의 균형점을 다르게 잡아야 했습니다.

- **EfficientNet-B0**: 모델 크기가 매우 작고 추론 속도가 가장 빠릅니다. 실시간성이 매우 중요한 경량 서비스나 모바일 클라이언트 단에 적용했습니다.
- **EfficientNet-B4**: 더 높은 정확도를 제공합니다. 높은 신뢰도가 필요한 핵심 필터링이나 서버 단의 배치 처리에 사용했습니다.

이처럼 상황에 맞는 모델을 유연하게 선택하는 전략을 통해, EfficientNet-B4를 기준으로 기존 테스트 모델 대비 유사한 정확도를 유지하면서도 추론 속도는 약 1.8배 빨라지고 모델 파라미터 수는 1/4 수준으로 감소시키는 등, 서비스 운영 효율을 실질적으로 개선할 수 있었습니다.

## 2차 발전: 스윈 트랜스포머 - 이미지의 '문맥'을 이해하다

CNN 기반 모델들은 이미지의 국소적인 패턴(Local Pattern)을 인식하는 데는 강하지만, 이미지 전체의 전역적인 관계나 문맥(Global Context)을 파악하는 데는 상대적인 약점이 있었습니다.

이에 대한 해결 전략으로 윈도우 기반 셀프 어텐션(Window-based Self-Attention)⁵을 택했습니다.

기존의 트랜스포머(Transformer) 모델을 이미지에 그대로 적용하기에는 한계가 있었습니다. 이미지의 모든 픽셀 조각들이 서로의 관계를 한 번에 계산하는 방식은 연산량이 너무 많아 비효율적이었기 때문입니다.

스윈 트랜스포머(Swin Transformer)⁶는 이 문제를 아주 영리한 방법으로 해결했습니다. 바로 이미지를 여러 개의 창문(Window, 윈도우)로 나누어 들여다보는 것입니다. 전체 이미지를 한 번에 분석하는 대신, 잘게 나뉜 창문 안에서만 픽셀 조각들의 관계를 계산합니다. 이렇게 하면 계산량이 획기적으로 줄어듭니다.

하지만 이 방식에는 한 가지 문제가 있습니다. 창문들은 서로 분리되어 있어, A 창문은 B 창문에서 무슨 일이 일어나는지 알 수 없습니다.

![Swin Transformer의 이동하는 Shifted Window 개념도, 출처 : Swin Transformer: Hierarchical Vision Transformer using Shifted Windows 논문 발췌]({{ site.baseurl }}/images/377e88a4019900001.png)

이 문제를 해결하기 위해 스윈 트랜스포머는 다음 단계에서 창문의 위치를 살짝 이동(Shift)시킵니다. 이렇게 창문을 겹치게 만들면, 이전 단계에서는 서로 다른 창문에 속해있던 픽셀 조각들이 새로운 창문 안에서 만나 관계를 맺을 수 있게 됩니다. 이 '고정된 창문'과 '이동하는 창문' 방식을 번갈아 사용함으로써, 계산 효율성은 높이면서도 창문 너머의 정보까지 놓치지 않고 이미지 전체의 문맥을 효과적으로 학습할 수 있게 됩니다.

결과적으로 스윈 트랜스포머도입 후 가장 큰 성과는 성능의 안정성이었습니다. 학습 및 검증 데이터셋에서 높은 성능을 보였던 모델이 실제 서비스에 배포되었을 때 성능이 저하되는 경우는 흔합니다. 하지만 스윈 트랜스포머는 예측 불가능한 실서버의 다양한 이미지에 대해서도 안정적인 지표를 유지하는 강건함(Robustness) 을 보여주었습니다. 특히, 이전에 자주 오탐하던 '애매한' 경계선 상의 이미지들에 대한 판별 능력이 크게 향상되었습니다.

## 핵심 발견: 모델 아키텍처 보다 중요한 것은 고품질의 라벨링 데이터

스윈 트랜스포머와 같은 최신 아키텍처를 도입하며 모델의 성능을 꾸준히 개선해 나갔습니다. 하지만 어느 시점부터 모델 구조 변경만으로 얻는 성능 향상 폭은 점차 줄어들고 있었습니다. 여전히 해결되지 않는 오탐 케이스들을 분석한 결과, 문제는 모델이 아니라 '데이터'에 있었습니다.

- **라벨링의 모호성**: '선정성'에 대한 기준을 라벨러마다 다르게 해석했습니다.
- **라벨링의 비일관성**: 같은 이미지가 다른 시점, 다른 라벨러에 의해 다른 라벨로 판정되는 경우가 있었습니다.

이 깨달음은 프로젝트의 방향을 180도 바꾸는 계기가 되었습니다. '모델 중심'에서 '데이터 중심'으로 사고의 패러다임이 전환되는 순간이었습니다. 더 나은 모델을 찾는 노력보다, 더 깨끗하고 일관된 데이터를 만드는 것이 성능 향상에 훨씬 더 큰 영향을 미친다는 것을 경험적으로 확인했습니다.

## AI를 위한 데이터 라벨링

AI 모델의 성능을 좌우하는 것은 결국 데이터의 품질입니다. 특히 유해 이미지 분류와 같은 도메인에 특화된 분야에서는 잘못된 라벨이 서비스 전체의 신뢰도를 흔들 수 있습니다. 하지만 고품질 라벨링 데이터를 확보하는 것은 생각보다 복잡한 문제였습니다.

가장 큰 문제는 비용과 시간이었습니다. 숙련된 라벨러 한 명이 하루에 처리할 수 있는 콘텐츠 량은 제한적이었고, 특히 복잡도가 높은 예외 케이스의 경우 상당한 검토 시간이 필요했습니다. 더욱이 라벨러 간 판단 기준이 달라 동일한 콘텐츠에 대해 서로 다른 결과를 내놓는 경우도 빈번했습니다.

이 문제를 세 가지 방향에서 해결하기로 했습니다. 첫째, 액티브 러닝(Active Learning)⁷을 통해 라벨링할 데이터를 지능적으로 선별하고, 둘째, 인지심리학 원리를 적용해 라벨러의 작업 환경을 개선하며, 셋째, AI가 사람의 판단을 보조하는 협업 시스템을 구축하는 것이었습니다.

## 액티브 러닝: 모델이 스스로 배울 데이터를 고르다

액티브 러닝(Active Learning)은 모델이 자신에게 가장 도움이 될 데이터를 선택하여 사람에게 라벨링을 요청하는 기법입니다. 핵심 아이디어는 모델이 이미 잘 맞추는 '쉬운' 데이터에 추가 라벨링을 하는 것보다, 모델이 헷갈려하는 '어려운' 데이터에 집중하는 것이 학습 효율을 높인다는 것입니다.

모델이 '어떤' 데이터를 선택할지 결정하는 쿼리 전략이 액티브 러닝의 성패를 좌우합니다. 여러가지 전략을 테스트 했고 최종적으로 두 가지 주요 전략을 중심으로 검토했습니다.

- **불확실성 샘플링(Uncertainty Sampling)**: 모델이 예측에 확신을 갖지 못하는 데이터를 우선적으로 선택하는 방법입니다. 이 중에서도 엔트로피 샘플링(Entropy Sampling)⁸ 방식을 적용했는데, 이는 모델의 예측 분포에서 엔트로피가 높은 샘플을 선택하는 방식입니다.
- **위원회 기반 질의(Query-by-Committee)**: 여러 모델로 구성된 '위원회'를 만들어, 위원들 간 의견이 가장 크게 엇갈리는 데이터를 선택합니다. 서로 다른 초기값으로 학습된 여러 모델의 예측 결과를 종합하여 가장 논란이 되는 케이스를 찾아내는 방식입니다.

**[쿼리 전략별 성능 및 운영 효율성 비교]**

| 쿼리 전략 | 라벨링 성능 향상 | 컴퓨팅 리소스 | 라벨링 대상 선정 속도 |
| --- | --- | --- | --- |
| 엔트로피 샘플링(Entropy Sampling) | ★★★ | ★ | ★★★★★ |
| 위원회 기반 질의(Query-by-Committee) | ★★★★ | ★★★★★ | ★ |

초기 검토에서 위원회 기반 질의(Query-by-Committee)가 라벨링 성능 향상에 더 큰 기여를 하는 것을 확인했습니다. 여러 모델의 '집단 지성'을 활용해 정말로 어려운 케이스를 효과적으로 찾아낼 수 있었기 때문입니다.

하지만 실제 운영 환경에서는 다른 요소들도 고려해야 했습니다. QBC는 여러 모델을 동시에 실행해야 하므로 GPU 메모리 사용량이 배수로 증가했고, 추론 시간도 그에 비례해 늘어났습니다. 하루에 처리해야 하는 이미지의 양을 고려할 때 이런 오버헤드는 현실적으로 감당하기 어려웠습니다.

반면 엔트로피 샘플링(Entropy Sampling) 방식은 위원회 기반 질의보다 성능 향상 폭은 작았지만, 여러 장점이 있었습니다.

- **리소스 효율성**: 단일 모델만 사용하므로 메모리 사용량 최소화
- **처리 속도**: 실시간에 가까운 빠른 처리 가능
- **운영 안정성**: 복잡한 모델 앙상블 관리 불필요
- **확장성**: 대용량 데이터 처리에 적합

결국 성능과 효율성 사이의 실용적 균형점을 찾아 엔트로피 샘플링 방식을 채택했습니다. 이는 완벽함 보다는 운영 가능한 차선책을 선택한 것이었지만, 실제 서비스 환경에서는 더 적합한 선택이었습니다.

## 인지심리학 기반 라벨링 도구 개선

기존 라벨링 도구는 라벨러들에게 과도한 정보를 동시에 제공하여 핵심 판단 업무에 집중을 방해하는 문제를 안고 있었습니다. 이를 해결하기 위해 인지심리학 이론을 바탕으로 라벨링 인터페이스를 전면 재설계했습니다.

라벨링 작업의 효율성을 저해하는 근본 원인을 파악하기 위해 기존 시스템의 인지 부하를 체계적으로 분석했습니다. 인지심리학의 인지부하 이론(Cognitive Load Theory)에 따르면, 인간의 작업 기억(Working Memory)은 동시에 처리할 수 있는 정보의 양이 제한적입니다. 밀러(Miller)의 연구에서 제시된 '7±2 법칙'처럼, 사람은 한 번에 5~9개의 정보 단위만을 효과적으로 처리할 수 있습니다.

기존 라벨링 도구를 분석한 결과, 한 화면에 10개 이상의 정보 요소가 동시에 노출되고 있었습니다. 대부분이 실제 라벨링 판단과는 직접적인 관련이 없는 부가적 정보들이었으며, 정작 중요한 이미지와 판단 버튼은 전체 화면의 일부분만을 차지하고 있었습니다.

**[인지부하 유형별 문제점 분석]**

| 인지부하 유형 | 기존 시스템 문제점 |
| --- | --- |
| 내재적 부하(Intrinsic Load) | 복잡한 판단 기준으로 인한 인지적 복잡성 |
| 외재적 부하(Extraneous Load) | 불필요한 UI 요소로 인한 주의 분산 |

또한, 라벨링 작업의 효율성을 저해하는 요인을 파악하기 위해 기존 시스템의 사용 패턴을 분석했습니다. 대부분의 이미지는 '이미지 확인 → 즉시 판단'의 2단계 프로세스로 충분히 처리 가능했지만, 기존 인터페이스는 이를 방해하는 구조로 설계되어 있었습니다.

작업 프로세스 분석:

- **이상적 프로세스**: 이미지 확인 → 즉시 판단 (대부분의 경우)
- **복잡한 케이스**: 이미지 확인 → 참고 정보 확인 → 판단 (내재적 부하가 높은 경우)
- **실제 기존 시스템**: 불필요한 정보 노출로 인한 인지적 방해

핵심 문제점은 라벨링 콘텐츠(이미지)가 차지하는 화면 비율보다 메타정보가 차지하는 비율이 과도하게 높다는 점이었습니다. 더 심각한 문제는 이러한 메타정보 대부분이 실제 라벨링 판단에는 전혀 도움이 되지 않는다는 점이었습니다.

예를 들어, “이미지 파일 크기가 텍스트로 노출될 필요가 있을까”, “업로드 시간 정보가 유해성 판단에 도움이 될까?”, “파일명이 라벨링 품질에 영향을 미칠까?”와 같은 의문이 드는 불필요한 정보들이 화면의 상당 부분을 차지하면서, 정작 중요한 이미지는 작은 영역에만 표시되었습니다. 또한 정말 필요한 참고 정보는 불필요한 메타 정보와 섞여있어 바로 인지하기 어려웠습니다.

## 라벨링 시스템의 UI/UX 재설계를 통한 문제 해결

기존 시스템 분석을 통해 다음과 같은 핵심 개선 방향을 설정했습니다.

- **이미지 중심 레이아웃**: 라벨링의 핵심인 이미지를 화면에 기존대비 크게 배치하여 즉시 집중할 수 있도록 했습니다.
- **불필요한 정보 제거**: 판단에 도움이 되지 않는 메타정보(RGB 값, 히스토그램, 이미지 사이즈 등)를 화면에서 제거했습니다.
- **AI 보조 정보 제공**
	- **시각적 근거 제시**: GradCAM을 통해 AI가 주목한 영역을 색상으로 강조
	- **유사 이미지 제공**: AI가 판단 근거로 활용한 유사 사례 이미지 노출
	- **텍스트 해석**: 이미지 내용을 텍스트로 해석하고 주요 단어를 색상으로 강조

우선, 기존 시스템의 복잡한 정보 구조를 다음과 같이 단순화했습니다.

**[정보 요소 우선순위 재정립]**

| 우선순위 | 정보 요소 | 배치 방식 | 개선 근거 |
| --- | --- | --- | --- |
| 1순위 | 메인 이미지 | 화면 왼쪽 대형 표시 | F 원리를 적용하여 라벨링의 핵심 대상 배치 |
| 2순위 | AI 보조 정보 | 우측 패널 | 판단이 어려운 경우 참고 |
| 제거 | 메타정보 | - | 판단에 불필요한 정보 |

화면 레이아웃도 다음과 같이 개선했습니다.

**[라벨링 인터페이스 개선 전후 비교]**

**개선 전:**

![]({{ site.baseurl }}/images/37879bb5019900001.png)

**개선 후:**

![]({{ site.baseurl }}/images/3787aec5019900001.png)

라벨링 시스템 재설계 시 아래의 AI 보조 기능을 함께 구현했습니다.

- **GradCAM 시각화**: AI가 판단에 영향을 준다고 생각하는 이미지 영역을 색상으로 강조하여 라벨러의 주의를 해당 부분에 집중시킵니다.
- **판단 근거 이미지 제공 ("노출이 적은 이미지")**: AI가 현재 이미지의 라벨을 판단할 때 도움이 된다고 생각하는 근거 정보를 이미지로 제공하여 라벨러의 판단을 보조합니다.
- **이미지 텍스트 해석**: "귀여운 스타일의 만화 캐릭터가 해변에서 손을 잡고 있는 모습을 보여줍니다"와 같이 이미지 내용을 텍스트로 해석하고, 주요 판단 요소를 색상으로 강조합니다.

나아가, 앨런 파이비오(Allan Paivio)의 이중 부호화 이론(Dual-coding Theory)⁹을 기반으로 시각적 정보와 언어적 정보를 함께 제공하도록 했습니다.

- **시각적 정보**: 이미지, GradCAM 히트맵, 유사 사례 이미지
- **언어적 정보**: 텍스트 해석, 주요 키워드 색상 강조
- **연결 구조**: 시각적 요소와 텍스트 설명을 공간적으로 연결 배치

이러한 구조를 통해 라벨러는 이미지를 보면서 동시에 AI의 해석을 참고할 수 있어, 더 정확하고 빠른 판단이 가능해집니다.

라벨링 시스템의 UI/UX를 개선하면서, 처음 설정했던 세 가지 목표를 모두 달성할 수 있었습니다. 첫 번째인 액티브 러닝(Active Learning)을 통한 데이터 선별로 효율적인 라벨링 대상을 선정하고, 두 번째로 인지심리학 원리를 적용한 작업 환경을 개선했으며, AI 가 사람의 인지능력을 보조하여 라벨링의 퀄리티를 높였습니다.

특히 주목할 점은 이제 AI와 사람이 각자의 강점을 살려 협업하는 구조가 만들어졌다는 것입니다. AI는 GradCAM을 통해 주목해야 할 영역을 제시하고, 이미지 내용을 텍스트로 해석하며, 판단에 도움이 될 근거 정보를 제공합니다. 사람은 이러한 AI의 보조 정보를 참고하여 최종 판단을 내리고, 그 결과가 다시 AI 학습에 활용되어 시스템 전체가 지속적으로 발전하는 선순환 구조를 만들어냈습니다.

직관적 인터페이스와 AI 보조 정보 제공을 통해 라벨러들이 보다 빠르고 정확하게 판단할 수 있는 기반을 마련했습니다. 특히 복잡도가 높은 예외 케이스에서 AI가 제공하는 시각적 근거와 텍스트 해석이 라벨러의 판단 품질 향상에 크게 기여했다는 점에서 이번 개선의 의의를 찾을 수 있었습니다.

-----

## 각주

1) Approximate K-Nearest Neighbors (AKNN)는 K-Nearest Neighbors (KNN) 알고리즘의 효율성을 개선한 방법입니다. 기존 KNN은 주어진 데이터 포인트(쿼리)와 데이터셋 내의 모든 다른 포인트 간의 거리를 계산하여 가장 가까운 K개의 이웃을 찾습니다. 데이터셋의 크기가 크거나 차원이 높을수록 이 계산량은 기하급수적으로 증가하여 엄청난 시간과 자원을 소모하게 됩니다. AKNN은 이러한 문제를 해결하기 위해 약간의 정확도를 희생하는 대신 검색 속도를 대폭 향상시키는 방식으로, 절대적으로 가장 가까운 K개의 이웃을 찾는 대신, 충분히 가까운 K개의 이웃을 효율적으로 찾아내는 방식입니다.

2) CNN(합성곱 신경망)은 이미지 인식 및 처리에 특화된 딥러닝 신경망입니다. 이미지에서 특징(선, 윤곽 등)을 자동으로 추출하고 학습하여 사물을 분류하거나 감지하는 데 사용됩니다. 합성곱 계층과 풀링 계층을 통해 이미지의 공간 정보를 효과적으로 유지하고 처리하는 것이 특징입니다.

3) EfficientNet은 적은 파라미터로 높은 정확도와 효율성을 달성한 CNN 모델입니다. 네트워크의 깊이(Depth), 너비(Width), 해상도(Resolution)를 균형 있게 확장하는 '복합 스케일링(Compound Scaling)' 방식을 사용하여 기존 모델보다 훨씬 효율적인 성능을 보여줍니다.

4) 복합 확장(Compound Scaling)은 EfficientNet에서 제시된 신경망 모델 확장(Scaling) 방법입니다. 기존에는 모델의 성능을 높이기 위해 네트워크의 깊이(Depth), 너비(Width), 또는 입력 이미지 해상도(Resolution) 중 하나를 독립적으로 늘리는 방식이 주로 사용되었습니다. 하지만 EfficientNet 연구팀은 이 세 가지 요소를 동시에, 균형 잡힌 비율로 확장하는 것이 훨씬 효율적이라는 것을 발견했습니다. Compound Scaling은 '복합 계수(Compound Coefficient)' (ϕ)라는 단일 변수를 사용하여 깊이, 너비, 해상도를 일정한 비율로 함께 증가시킵니다. 이를 통해 모델의 성능을 극대화하면서도 계산 자원의 효율성을 유지할 수 있습니다. 예를 들어, 이미지가 크면 더 깊은 네트워크로 더 넓은 영역을 보고, 더 많은 채널로 상세한 특징을 잡는 식입니다.

5) 기존 트랜스포머의 셀프 어텐션은 이미지 전체 픽셀 간의 관계를 계산하여 이미지 크기가 커질수록 계산량이 기하급수적으로 증가하는 문제가 있었습니다. 윈도우 기반 셀프 어텐션은 이미지를 여러 개의 작은 '윈도우(Window)'로 나누고, 각 윈도우 내에서만 셀프 어텐션을 수행하여 계산 복잡도를 크게 줄이는 방식입니다.

6) 스윈 트랜스포머(Swin Transformer)는 이미지 처리에 특화된 트랜스포머 모델입니다. 기존 Vision Transformer(ViT)의 높은 계산 복잡도 문제를 해결하기 위해 계층적 구조(Hierarchical Architecture)와 Shifted Window 개념을 도입했습니다. 이를 통해 이미지의 다양한 스케일 정보를 효율적으로 학습하고, 객체 탐지나 분할과 같은 복잡한 비전 태스크에서도 뛰어난 성능을 보입니다. Swin Transformer는 Window-based Self-Attention을 핵심 구성 요소로 사용합니다. 특히, Shifted Window 기법을 통해 인접한 윈도우 간의 정보 교환을 가능하게 하여, 윈도우 내에서만 어텐션을 수행하는 한계를 극복하고 이미지 전체의 맥락을 효과적으로 파악할 수 있도록 합니다. 즉, Swin Transformer는 윈도우 기반 셀프 어텐션의 효율성을 활용하면서도 Shifted Window를 통해 더 넓은 범위의 정보 교환을 가능하게 하여 이미지 처리 성능을 극대화한 모델입니다.

7) 액티브 러닝(Active Learning)은 적은 양의 라벨링된 데이터로 머신러닝 모델의 성능을 최대한으로 끌어올리는 학습 전략입니다. 일반적인 지도 학습은 모든 데이터에 라벨을 사람이 직접 부여해야 하지만, 대규모 데이터셋에서는 라벨링에 막대한 시간과 비용이 듭니다. 액티브 러닝은 이 문제를 해결하기 위해 모델이 가장 학습에 도움이 될 만한(정보량이 많은) 데이터를 스스로 선별하여 사람에게 라벨링을 요청합니다. 이러한 반복적인 과정을 통해 액티브 러닝은 라벨링 비용을 절감하면서도 모델의 정확도를 빠르게 향상시키는 데 효과적입니다.

8) 엔트로피 샘플링은 모델의 예측 결과 중 엔트로피(불확실성, 무질서도)가 가장 높은 데이터를 선택하여 라벨링을 요청하는 전략입니다. 엔트로피가 높다는 것은 모델이 특정 클래스로 확신하지 못하고 여러 클래스에 대해 비슷하게 확률을 분배한다는 의미이므로, 이런 데이터를 학습하면 모델의 불확실성을 효과적으로 줄일 수 있습니다.

9) 앨런 파이비오(Allan Paivio)의 이중 부호화 이론(Dual-coding Theory)은 인간의 뇌가 정보를 언어(글, 말)와 이미지(그림, 시각) 두 가지 방식으로 처리하고 저장한다는 이론입니다. 이 두 방식이 함께 사용될 때 기억이 더 잘 되고 오래 남습니다.
