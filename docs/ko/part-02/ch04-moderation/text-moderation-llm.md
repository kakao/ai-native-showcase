---
layout: default
title: '4.2. 텍스트 콘텐츠의 수호자: 모니터링 보조 LLM의 이야기'
lang: ko
parent: '제4장. AI 콘텐츠 모더레이션 - 쾌적한 세상을 위한 AI의 노력'
nav_order: 2
permalink: /ko/part-02/ch04-moderation/text-moderation-llm/
author: zoey.fully
---

# 4.2. 텍스트 콘텐츠의 수호자: 모니터링 보조 LLM의 이야기

이 장에서는 텍스트 기반 유해 콘텐츠 모니터링에 AI, 특히 LLM이 어떻게 혁신을 가져왔는지를 다룹니다. 내부적으로 '하몽(jamon)'이라는 프로젝트명으로 진행된 이 시스템은 스팸(spam)의 반대 개념인 햄(ham)에서 착안하여 명명했습니다.

## "이걸 사람이 다 본다고?" — 장문 속 숨겨진 한 줄의 함정

"이걸 사람이 다 본다고?" — 수많은 사용자가 올리는 게시글과 댓글, 그리고 리뷰 등의 텍스트 콘텐츠는 그 양만큼이나 다양하고 복잡합니다. 

특히 수십, 수백 줄에 달하는 장문 게시글의 경우, 운영자가 일일이 모든 내용을 꼼꼼히 파악하며 유해성 여부를 판단하는 것은 엄청난 피로도를 유발하는 작업이었습니다. 글의 시작과 끝은 정상적이지만, 중간에 교묘하게 숨겨진 불법 광고나 사기성 정보가 삽입된 경우도 많아 사람의 눈으로는 놓치기 쉬웠습니다.

이 때문에 스팸 사유를 설명해주는 모델이 필요했고 LLM은 뛰어난 문맥 이해 능력을 갖추고 있었습니다.

먼저, 스팸인지 아닌지를 확인하는 단순한 이진 분류만으로는 운영자에게 충분한 정보를 제공하지 못했습니다. 예를 들어 "오늘은 떡볶이가 맛있습니다. ..생략.. (저희 카지노에 오세요: 링크) ..생략.. 분당 떡볶이 맛집 #음식 #추천"과 같은 글을 단순히 ‘스팸’으로 분류할 경우, 운영자는 “음식 후기인데 왜 스팸으로 분류했지?”하며 오탐을 할 가능성이 있습니다. 

이때 LLM에게 설명을 추가하도록 하면 음식 후기로 위장했지만 중간에 카지노 링크가 삽입되어 있어 불법 도박 홍보 목적의 스팸임을 바로 확인할 수 있습니다.

또한, LLM의 경우, 적은 데이터로도 복잡한 문맥을 정확하게 파악하는 데다, 특정 패턴 학습에 많은 데이터가 필요한 기존 모델에 비해 적은 데이터로도 새로운 패턴과 복잡한 문맥 이해가 가능해 다양한 말투와 변형된 유해 단어에 대응을 잘합니다.

![]({{ site.baseurl }}/images/3772f503019900001.png)

### 카카오 최초 LLM 도입 의사결정

이 모니터링 보조 LLM은 비록 사용자에게 직접적인 서비스를 제공하는 것은 아니었지만, 카카오 내부 서비스 환경(프로덕션 환경)에 LLM이 적용된 최초의 사례 중 하나였습니다. LLM의 활용 방안은 무궁무진하지만, 기존의 잘 작동하는 시스템을 굳이 LLM으로 대체하는 것은 여러 면에서 부담이 따를 수 있었습니다.

하지만 이 시스템은 운영자를 대신하는 것이 아니라, 운영자와 함께 일하는 동료 같은 개념이었습니다. 기존에 없던 '설명'이라는 새로운 기능을 추가하여 운영자의 업무를 도와주는 어시스턴트 역할이었습니다. 상담원을 대신하는 상담봇처럼 명확한 성능 기준이나 완벽함을 요구받지 않았기 때문에, 비교적 안전하게 실험적으로 LLM을 도입하고 그 효과를 검증할 수 있었습니다.

### 운영자와 함께 하는 AI 만들기

![]({{ site.baseurl }}/images/3774ac4f019900001.png)

초기에는 단순히 AI가 유해 콘텐츠를 자동으로 빠르게 차단하는 것에 집중했습니다. 하지만 운영자들의 피드백을 들으면서 '왜 이렇게 분류되었는지'에 대한 설명이 부족하여 오탐 시 혼란이 크다는 점을 파악했습니다.

![]({{ site.baseurl }}/images/3775bc83019900001.png)

운영자의 업무는 계속 존재하며, 이들이 더 나은 판단을 할 수 있도록 도와주는 도구의 필요성을 절감했습니다. 단순히 유해성 여부를 '판단'하는 것을 넘어, '왜' 유해한지 설명함으로써 운영자가 더 빠르고 정확하게 업무를 처리할 수 있도록 돕는 것이 핵심이었습니다.

이러한 ‘운영자와 함께 일하는 AI 구축’은 이후 시스템 구축의 모든 단계에서 핵심 가이드라인이 되었으며, 기술적 성능도 중요하지만 실제 사용자(운영자)의 니즈를 정확히 파악하고 반영하는 것이 성공적인 AI 시스템 구축의 핵심임을 확인할 수 있었습니다.

## "너는 스팸 분류 AI Bot이야" — 원하는 대로 답하는 모델 만들기

스팸 분류 AI 챗봇 개발팀은 80억 개 매개변수를 가진 기본 모델을 활용하여 콘텐츠 모더레이션 AI를 만들었습니다. 이 모델은 성능, 속도, 비용 효율성을 고려한 선택이었습니다. 특히, A100 80GB GPU 환경에서 양자화 없이도 안정적인 추론이 가능하여 개발 유연성이 높았습니다.

### 데이터셋 설계와 투트랙 전략

모델은 지시문 튜닝 기반 학습을 통해 다양한 지시사항을 이해하고 그에 맞는 응답을 생성하도록 훈련받았습니다. 핵심은 하나의 모델이 사용 목적에 따라 다른 형식의 응답을 제공하도록 하는 것이었습니다.

- **실시간 분류**: 스팸 여부를 0 또는 1로 간단히 응답하여 빠른 처리와 비용 효율성을 확보했습니다.
- **모니터링 보조**: 스팸 여부와 함께 요약, 키워드, 규제 사유 등을 JSON 형식으로 상세하게 설명하여 운영자의 모니터링 효율을 높였습니다.

### 학습과 최적화

효과적인 학습을 위해 단순히 스팸 여부만 라벨링하는 것을 넘어, ‘왜’ 스팸인지에 대한 구체적인 설명 데이터를 구축했습니다. 이를 위해 라벨링 가이드라인을 정교화하고, 전문가 교차 검토 시스템을 도입하며, 모델을 활용한 검증 방식을 적용하여 데이터 품질을 높였습니다.

또한, 모델이 다양한 표현에 유연하게 대응하도록 표현 다양화 전략을 사용했고, 실제 환경에서 흔한 데이터 불균형 문제 해결을 위해 ‘베이스라인’, ‘패턴 증강’, ‘다중 클래스’ 방법을 비교 실험하여 분류 경계에 위치한 애매한 데이터 증강이 가장 효과적임을 확인했습니다.

### 운영 안정성과 효율성 향상

모델의 추론 비용을 최적화하기 위해 텍스트 압축, 핵심 문장 추출, 단일 토큰 출력, 전용 토큰 추가 등의 토큰 길이 최적화 기법을 적용했습니다. JSON 출력의 안정성을 위해 학습 단계에서 데이터 일관성을 유지하고, 추론 단계에서는 예외 처리를 강화했으며, 후처리 파이프라인에서 스키마 검증 및 파싱 에러 복구를 구현했습니다.

신조어와 은어 대응을 위해 의심 단어 자동 마킹 기능을 개발하여 운영자가 빠르게 인지할 수 있도록 도왔습니다.

## "왜 이게 스팸이야?" — 운영자가 원했던 AI의 설명

![]({{ site.baseurl }}/images/37772daf019900001.png)

AI 모델이 아무리 뛰어나도 100% 완벽할 수는 없습니다. 특히 AI이 '의심스럽다'고 판단하여 운영자에게 우선순위로 넘긴 콘텐츠 중에는 실제로는 유해하지 않은 오탐도 존재합니다. 이 경우 운영자는 AI이 왜 이 콘텐츠를 유해하다고 판단했는지 맥락을 파악하기 어려워 혼란을 겪거나, 불필요한 재검토에 시간을 낭비할 수 있습니다.

이러한 운영자의 어려움을 해소하고 오탐으로 인한 피로도를 줄이기 위해, 모니터링 보조 LLM은 단순 분류를 넘어 '유해성 판단의 근거를 자연어로 설명하는' 핵심 기능을 제공합니다.

콘텐츠 예시:

> "안녕하세요! 혹시 요즘 코인으로 수익 내는 방법 찾고 계신가요? 😮 저희 '슈퍼코인 투자클럽'에서 놀라운 수익률을
> 경험해보세요. ✨ 안전하게, 빠르게, 그리고 확실하게! 📈 (실제 투자 수익률 인증 사진 첨부 예정). 지금 바로
> 참여하세요! ▶️ [단독 비공개 리딩방 링크 포함: bit.ly/불법투자방] 이곳에서만 얻을 수 있는 정보와 전략을
> 알려드립니다. 문의는 텔레그램 @supercoinmaster 로 주세요. #코인투자 #재테크 #비트코인 #대박수익
> #재테크노하우"

**LLM 분석 결과 (JSON 형태 예시):**

```
{
    "규제": true,
    "요약": "투자 유도 및 외부 리딩방 가입 권유",
    "키워드": ["코인", "수익", "투자클럽", "단독 비공개 리딩방", "불법투자방"],
    "규제사유": "불법 사행성 카지노 홍보"
}
```

이 LLM 기반 시스템은 이처럼 '규제', '요약', '키워드', '규제사유' 등의 형태로 핵심 정보를 추출하여 운영자가 보기 좋고 이해하기 쉽게 제공합니다.

## 콘텐츠 모더레이션에 AI를 활용한다면

가장 주목할 만한 성과는 운영자의 모니터링 효율성 향상입니다. 기존에는 운영자가 신고된 콘텐츠를 검토할 때 해당 콘텐츠의 전체 맥락을 파악하고 유해성 여부를 판단하는 데 상당한 시간과 집중력이 필요했습니다. 하지만 LLM이 제공하는 구조화된 분석 결과를 통해 모니터링 시 고민하는 시간이 기존 대비 20% 이상 단축되는 효과를 확인할 수 있었습니다.

또한, 적절한 데이터 불균형 해결 전략을 적용했을 때 기존 대비 상당한 성능 향상을 달성할 수 있었습니다. 특히 스팸 탐지율과 전반적인 분류 정확도에서 의미 있는 개선을 확인했습니다. 

스팸과 유사한 패턴을 가진 데이터를 추가한 실험군에서는 모든 평가 지표에서 현저한 성능 향상을 확인할 수 있었으며, 특히 재현율(Recall)의 대폭적인 개선은 모델이 다양한 스팸 변형을 더 잘 탐지할 수 있게 되었음을 시사합니다.

더 중요한 것은 실제 운영 환경에서의 효과입니다. 개선된 모델은 운영자의 모니터링 업무 효율성을 크게 향상시켰으며, 오탐으로 인한 불필요한 검토 시간을 줄이는 데 기여했습니다.

이번 개발을 통해 운영 효율성 향상과 스팸 탐지율 및 전반적인 분류 정확도 개선이라는 두 가지 주요 성과를 달성했습니다. 특히 재현율의 대폭적인 개선은 모델이 다양한 스팸 변형을 더 잘 탐지하게 되었음을 의미합니다.
