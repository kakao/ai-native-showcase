---
layout: default
title: '5.1. AI 데브옵스 시스템, 카카오릴리즈'
lang: ko
parent: '제5장. AI가 바꾸는 데브옵스 환경'
nav_order: 1
permalink: /ko/part-02/ch05-devops/kakaorelease-devops/
author: marron.b, ricky moon
---

# 5.1. AI 데브옵스 시스템, 카카오릴리즈

AI는 배포 및 운영 환경에 실질적인 변화를 가져왔습니다. 덕분에 카카오의 데브옵스 문화 역시 더욱 가속화되고 서비스의 안정성도 개선되고 있습니다.

AI가 어떻게 카카오의 배포 워크플로를 효율화하고, 운영 환경을 예측 가능하게 만들며, 나아가 시스템 스스로 문제를 해결하는 자율적인 운영 시대를 향해 도전하고 있는지 카카오의 실제 경험과 기술적 도전 과제 해결을 중심으로 살펴보겠습니다.

## AI 기반 릴리즈 관리: 자동 문서화와 리스크 분석

기존 배포 관리 방식은 여러 문제점을 안고 있었습니다. 누가, 무엇을, 언제 배포하는지에 대한 정보가 파편화되어 있고, 다른 서비스에 영향을 미치는 배포 및 작업이 전사에 충분히 공유되지 않아 예기치 못한 문제가 발생하기도 했습니다. 

특히 수많은 서비스가 복잡하게 연결된 카카오의 환경에서는 예측 불가능한 서비스 의존성으로 인한 문제가 빈번했고, 인프라 작업은 전체 서비스에 광범위한 영향을 미칠 수 있었습니다. 

또한, 배포 계획 수립 후 수동 리뷰 과정에서 미처 파악하지 못한 위험이 존재하거나, 긴급 배포 시 검토 부족으로 장애 발생률이 증가하는 등의 한계가 명확했습니다.

카카오는 이러한 문제를 해결하고 배포 워크플로를 재정의하기 위해 AI 기반 배포 관리 플랫폼 ‘카카오릴리즈’를 구축해서 운영하고 있습니다. 카카오릴리즈는 배포 계획 수립부터 배포 실행, 그리고 실행 후 즉각적인 모니터링까지 일련의 과정에서 AI와 긴밀하게 협업하여 안전한 배포를 가능하게 합니다.

카카오릴리즈의 핵심적인 역할 중 하나는 배포 계획 문서 작성 및 리뷰 자동화입니다. 기존에 시간이 가장 많이 소모되고 품질의 편차가 컸던 문서 작성 및 리뷰 영역을 AI가 어떻게 해결하고 있는지 알아보겠습니다.

![기존의 배포 워크플로의 각 단계와 카카오릴리즈의 AI가 변화시킨 단계]({{ site.baseurl }}/images/37eb981a019900001.png)

### 복잡한 배포/작업 노트, AI 에이전트로 자동 작성하기

앞서 소개한 카카오릴리즈에서 가장 먼저 AI가 투입된 영역이 바로 배포/작업 노트 작성입니다. 일반적으로 릴리즈 노트는 변경사항 요약, 새로운 기능, 버그 수정 등의 정보를 포함합니다. 

그러나 카카오처럼 수 많은 서비스가 복잡하게 연결된 환경에서는 한 서비스의 배포가 다른 서비스에 미치는 영향도 미리 파악하는 것이 중요합니다. 이를 위해 카카오는 일반적인 릴리즈 노트보다 상세한 문서를 작성합니다.

배포 노트는 애플리케이션 코드 배포 시 작성하고, 작업 노트는 데이터베이스 버전 업그레이드, 서버 교체, 인증서 갱신 등 주로 인프라 작업 시 작성합니다. 

이 문서들은 배포/작업의 변경 사항 및 영향 범위, 롤백 전략 및 시나리오, 모니터링 시나리오, 배포/작업 담당자, 배포/작업 전 후 체크리스트 등이 포함됩니다. 덕분에 개발자들은 해당 배포나 작업이 유관 부서에 어떤 영향을 미칠지 사전에 파악할 수 있습니다.

하지만 안전한 배포/작업을 위해 포함되어야 하는 정보가 많아지면서 문서 작성이 복잡하고 시간이 오래 걸리게 되었습니다. 또한 작성자에 따라 중요 정보가 누락되거나, 조직마다 다른 작성 양식을 사용하여 일관성이 부족한 경우도 있었습니다. 이러한 문제를 해결하기 위해서 AI를 활용한 배포/작업 노트 자동 작성 기능을 개발했습니다.

![카카오릴리즈 AI의 노트 생성 프로세스]({{ site.baseurl }}/images/37ec3978019900001.png)

AI가 배포/작업 노트를 생성하는 과정은 ① GitHub, Jira에서 데이터 수집, ② Summary AI가 수집된 데이터를 요약하고 이를 기반으로 Generate AI가 초안을 생성, ③ RAG에 저장된 스키마를 참고하여 출력의 형태를 구성하는 3 단계의 순서로 진행됩니다.

**① 데이터 수집 단계**

- 사용자가 입력한 GitHub 브랜치 혹은 태그에서 Commit diff 추출
- 이번 배포의 변경 사항 및 변경 범위의 규모 파악
- 배포 대상 커밋과 관련된 풀 리퀘스트 식별
- JIra 이슈에서 제목, 설명, 담당자, 인수조건(Acceptance Criteria) 등 분석하여 기획 의도와 개발 목적 파악
- 해당 워크스페이스¹에서 최근 작성한 배포/작업 노트 5건 분석

**② AI 처리 단계**

- 서머리(Summary) AI가 수집된 데이터 요약
- 제너레이트(Generate) AI가 병렬로 노트 자동 생성
- 병렬 처리와 컨텍스트 압축을 통해 처리 속도 약 75% 향상

**③스키마 적용 단계**

- RAG에 저장된 스키마 참고 하여 출력 형태 구성
- 형식 검증 및 후처리 완료

![카카오릴리즈 AI 초안 생성 아키텍처]({{ site.baseurl }}/images/37ed6ac7019900001.png)

초기에는 GitHub과 Jira에서 관련 컨텍스트를 추출하여 LLM에 입력하면, 바로 완성된 결과가 나올 것이라고 예상했습니다. 복잡한 처리 과정 없이도 만족할 만한 결과를 얻을 수 있을 것이라 기대했기 때문에 아키텍처는 간단하게 구성했습니다.

하지만 실제 구현 과정에서는 예상보다 더 많은 엔지니어링 작업이 필요했습니다. 대용량 컨텍스트를 효율적으로 압축하여 전달해야 했고, 여러 API 호출과 AI 처리를 실행하다 보니 응답이 지연되는 문제가 발생했습니다. 또한 원시 데이터의 노이즈로 인해 컨텍스트의 품질이 저하되었고, 출력된 결과물의 품질과 형식이 매번 달라지는 문제도 있었습니다.

**① 토큰 제한 문제와 대용량 컨텍스트 압축 기법**

LLM의 컨텍스트 윈도우는 크게 늘어났지만(GPT-4: 128k, Claude-3: 200k), 여전히 압축은 필요합니다. 입력 토큰 비용이 출력 토큰보다 저렴해지고 있는 추세이긴 하지만, 토큰 수가 누적되면 누적될수록 비용은 크게 증가합니다. 

또한 처리 시간은 토큰 수에 비례해서 증가하기 때문에 토큰 수는 가능한 적게 유지하는 방향으로 아키텍처를 구성하고 기능을 구현하는 것이 비용 효율성과 성능을 확보할 수 있는 방법입니다. 

이를 위해서는 최소한의 토큰으로도 정보의 누적 없이 핵심을 처리할 수 있도록 핵심 정보에 집중하는 것이 필요합니다. 이는 응답 품질의 향상과도 관련이 있습니다.

각 Jira 이슈 및 GitHub 정보에서 초안 작성에 필요한 핵심 데이터만을 추출한 뒤, 이를 독립적인 청크²로 분할하여 ‘서머리 AI’를 통해 비동기 병렬 처리 방식으로 요약합니다. 또한 최근 작성된 배포/작업 노트 5건에서도 필요한 정보만을 추출해 동일한 방식으로 요약합니다.

이처럼 입력 데이터를 정제하고 요약함으로써, 컨텍스트는 핵심 내용 중심으로 구성되었습니다. 특히 Jira 이슈와 GitHub 정보는 약 44,000 토큰에서 2,300 토큰으로 약 95% 압축되어, 불필요한 정보를 줄이고 내용의 품질을 효과적으로 향상시킬 수 있었습니다.

![서머리 AI 요약 처리 아키텍처]({{ site.baseurl }}/images/37eeb0b1019900001.png)

**② 병렬 처리를 통한 결과 품질 향상 및 응답 지연 최소화**

초기에는 배포노트 초안 작성을 위해 Jira, GitHub, 최근 배포 내역 등 다양한 소스에서 수집한 정보를 하나의 긴 컨텍스트로 AI에 전달했습니다. 이 방식은 응답 시간이 길어지고, AI가 핵심 내용을 효율적으로 이해하지 못해 품질이 저하되는 문제가 있었습니다.

AI의 처리 한계를 고려해 초안 작성을 위한 정보를 논리적인 4가지 단위로 분류했습니다. 즉, 기본정보, 체크리스트, 본문 내용, 배포 대상 리포지토리 정보의 네 파트로 나누어, 각 파트를 독립적인 요청으로 병렬 처리함으로써 AI가 각 요청에 집중할 수 있도록 구성했습니다.

단순히 AI에 모든 걸 맡기는 것이 아니라, 데이터 구조화와 병렬화라는 엔지니어링 최적화가 핵심임을 깨달았습니다. 그 결과 초안 품질은 향상되었고, 처리 속도는 평균 120초 이상에서 30초 이내로 약 80% 개선되었습니다.

![제너레이트 AI 초안 생성 아키텍처]({{ site.baseurl }}/images/37ef2ca0019900001.png)

**③ 퓨샷 러닝(Few-shot Learning)의 실제 적용 사례**

초안 작성을 위해 먼저 사용자의 노트 작성 방식을 살펴본 결과, 사용자마다 톤앤매너, 문장 구성, 필드 사용 방식이 제각각이었습니다. 또한 시스템 내부적으로 정의된 필드별 최대 길이(maxLength)나 데이터 타입과도 불일치가 있어, AI가 생성한 초안은 일관성을 유지하기 어려웠고, 후처리 비용도 높아지는 문제가 있었습니다.

이를 해결하기 위해 우수 사례를 퓨샷(Few-shot)³ 예시로 제공하고, 명확한 스키마를 정의해 RAG에 적용함으로써, 출력 형식과 표현 스타일의 통일을 동시에 달성할 수 있었습니다. 많은 샷 없이도 충분히 높은 품질의 결과를 얻었으며, 스키마 기반 출력으로 후처리 작업은 크게 줄고 결과의 정합성은 높아졌습니다.

결과적으로 톤앤매너의 정합성 확보, 출력 포맷의 일관성 유지, 구조화된 데이터 기반 후처리 효율화라는 세 가지 측면에서 의미 있는 개선 효과를 이끌어냈습니다.

**[퓨샷 러닝을 위한 스키마 예제]**

```
{
	"type": "object",
	"description": "배포 노트 초안 생성을 위한 입력 스키마입니다. noteDetails, checklistGroup, agitIntegrations, matr"+"ixIntegrations로 구성됩니다.",
	"properties": {
		"noteDetails": {
			"type": "object",
			"required": [],
			"description": "배포 노트의 주요 필드.",
			"properties": {
				"title": {
					"type": "string",
					"maxLength": 100,
					"description": "배포 노트 제목. 행동 지침을 준수하여 생성"
				},
				"content": {
					"type": "string",
					"default": "",
					"maxLength": 10000,
					"description": "리뷰어가 인지해야 하는 주요 배포 내용. 행동 지침을 준수하여 생성"
				},
				"rollbackStrategy": {
					"type": "string",
					"default": "REDEPLOY_NO_BUILD",
					"enum": [
						"REDEPLOY_NO_BUILD", "REDEPLOY", "CANARY", "BLUE_GREEN", "ETC"
					],
					"description": "롤백 전략"
				}
			}
		},
		"checklistGroup": {
		// 중략
		},
		"agitIntegrations": {
		// 중략
		},
		"matrixIntegrations": {
		// 중략
		}
	}
}
```

![기술 과제 3가지와 해결책]({{ site.baseurl }}/images/37f412dc019900001.png)

### 인간과 AI의 협업으로 리뷰 프로세스 재구성

AI는 배포/작업 노트 초안을 자동으로 생성하는 것 뿐만 아니라, 작성된 노트를 리뷰하여 잠재적 리스크를 사전에 파악하고 위험도를 판별합니다. 이러한 리뷰 과정을 거쳐서 배포 프로세스 전반의 안전성을 높일 수 있습니다.

기존의 노트 리뷰는 리뷰어의 경험에 의존했습니다. 운영팀이 과거 경험을 바탕으로 “이런 변경사항은 위험할 수 있다”고 판단하거나, 체크리스트를 하나씩 확인하며 놓친 부분은 없는지 검토하는 방식이었습니다. 하지만 이런 방식은 리뷰어의 경험과 컨디션에 따라 품질이 달라집니다. 특히 긴급 배포 상황에서는 충분한 검토 시간을 확보하기 어렵다는 문제점이 있었습니다.

카카오릴리즈는 이러한 한계를 극복하기 위해 AI 기반 자동 리뷰 시스템을 구축했습니다. 이 시스템은 과거 약 500건 이상의 장애 사례를 벡터 DB에 저장한 뒤 현재 배포 계획에서 유사한 위험 패턴을 찾아내고, 전사 배포 일정을 자동 감지 및 분석하여 충돌 가능성을 예측하며, 안전한 배포를 위해 수립한 정책인 ‘릴리즈 스탠다드’ 준수 여부를 자동으로 검증합니다.

특히 AI 리뷰가 도움이 되는 부분은, AI가 단순히 정책 충족 여부를 검증하는 것을 넘어서 “왜 위험한지” 설명하고 “어떤 대안이 있는지”를 제안한다는 점입니다. 

예를 들어 인증서 교체와 관련된 작업 노트의 경우에는 인증서 만료 시간을 알려주며 이를 확인하라고 조언하거나, 같은 날 동일한 시간대의 배포/작업 계획들을 요약해서 보여주며 잠재적 리스크를 평가하는 등 실용적인 조언을 제공합니다.

이러한 AI 리뷰하는 과정은 ① 장애일지 수집, ② 컨텍스트 수집, ③ AI 리뷰 3 단계로 진행됩니다.

**① 장애일지 수집**

배포/작업 노트를 리뷰할 때, 같은 실수를 반복하지 않도록 과거 장애 사례를 자동으로 참조하면 좋겠다는 니즈가 있었습니다. 그러나 기존에는 장애일지가 장문 형태로 분산되어 저장되고 있었고, 리뷰 시 실시간으로 이를 연결하거나 활용할 수 있는 구조는 갖춰지지 않았습니다.

이를 해결하기 위해 아지트(사내 협업 플랫폼)에 등록되는 장애일지를 웹훅 기반으로 자동 수집하고, 리캡(Recap) AI를 통해 핵심 정보만 요약한 뒤, 이를 벡터로 임베딩하여 RAG 시스템에 저장하는 프로세스를 구축했습니다. 

이렇게 구축된 벡터 DB는 AI가 배포/작업 노트를 리뷰할 때 실시간으로 검색되어 맥락에 맞는 과거 장애 사례를 자동으로 참조할 수 있게 합니다. 사용자는 별도로 장애일지를 검색하지 않아도 되고, AI는 더 풍부한 문맥을 기반으로 리뷰 의견을 생성할 수 있습니다.

이러한 구조를 통해, 기존에는 연결되지 않았던 장애일지와 노트 리뷰가 하나의 흐름으로 통합되었습니다. 그 결과, AI가 작성하는 리뷰는 단순히 노트 자체만 평가하는 것이 아니라 과거의 조직적 경험을 참고하는 방향으로 진화하게 되었고, 반복 가능성이 있는 위험을 사전에 짚어주는 역할도 가능해졌습니다. 

장애 대응의 맥락이 노트에 자연스럽게 녹아들면서, 리뷰의 깊이와 신뢰도 모두 눈에 띄게 향상되었습니다.

![장애일지 수집 프로세스]({{ site.baseurl }}/images/37f4f96c019900001.png)

**② 컨텍스트 수집**

AI가 리뷰를 수행할 수 있도록 하기 위해, 사전에 다양한 정책 관련 데이터를 수집하고 정리했습니다. 먼저, 리뷰 요청된 작업이나 배포가 전사에 영향을 미치는 다른 일정과 겹치는지 확인하기 위해 전체 릴리즈 캘린더와 작업 일정을 비교해 충돌 여부를 추출했습니다.

또한, 릴리즈 스탠다드 정책에 따라 다음과 같은 항목들을 점검 가능한 형태로 수집했습니다.

- 다중 담당자 여부: 2명 이상의 운영자 지정 필수
- 모니터링 가능 시간대: 평일 근무시간 또는 모니터링 가능한 시간
- 체크리스트 그룹: 작업 유형에 따른 필수 체크리스트 존재
- 필수 리뷰어: 작업 영향도에 따른 리뷰어 레벨 요구사항

**③ AI 리뷰**

AI 리뷰는 하이브리드 접근을 통해 리뷰 효율성과 품질을 동시에 높이는 방식을 사용했습니다. 알고리즘의 정밀한 규칙 검토 능력과 AI의 유연한 추론 능력을 결합해 워크플로를 구성했습니다.

우선 ‘② 컨텍스트 수집’ 단계에서는, 전사에 영향을 미치는 다른 서비스의 배포 및 작업 일정과의 충돌 여부를 자동으로 감지하고, 릴리즈 스탠다드 정책 준수 여부를 점검합니다. 이 과정은 알고리즘이 중심이 되어 수행되며, 정책 위반이나 일정 간섭과 같은 명확한 규칙 기반 문제를 빠르고 정확하게 검토해줍니다.

과거 장애 사례에 대한 분석은 AI가 담당해줍니다. 텍스트 유사도 기반 검색을 통해, 현재 작업과 유사한 과거 이슈를 찾아주고, 잠재적인 위험이나 누락된 고려 사항을 사전에 인지할 수 있도록 도와줍니다.

알고리즘이 규칙 기반 문제를 빠르고 정확하게 처리하고, AI가 데이터 기반의 유연한 통찰을 제공해주는 하이브리드 접근을 통해 리뷰 품질은 높아지고 운영 리스크는 최소화되는 효과를 얻을 수 있었습니다.

![AI 리뷰 프로세스]({{ site.baseurl }}/images/37f6d721019900001.png)

![AI 리뷰 아키텍처]({{ site.baseurl }}/images/37f6f21b019900001.png)

![AI 리뷰 서비스 화면]({{ site.baseurl }}/images/37f70c64019900001.png)

## 카카오릴리즈의 완전 자동화를 향한 비전

카카오릴리즈는 노트 작성, 리뷰, 배포 및 모니터링 등 배포 워크플로 전체를 AI 에이전트와 시스템이 자동화하여, 개발자가 릴리즈 노트를 작성하지 않고, 개발에 더욱 집중할 수 있는 시간을 확보하는 것을 목표로 합니다. 

이를 위해 배포 계획 수립 및 리뷰를 넘어 배포 후 운영의 영역까지 AI를 활용하고 있습니다. 실제 운영 환경에서는 예상치 못한 변수들이 발생하며, 특히 배포 직후부터 24시간까지는 서비스의 안정성을 반드시 모니터링해야하는 중요한 시간대입니다.

기존에는 이 시간 동안 개발자와 운영팀이 직접 모니터링 대시보드를 주시하면서 수동으로 서비스 상태를 확인했습니다. 에러율 증가, 응답시간 지연, 트래픽 패턴 변화 등을 확인하고 이들 간의 상관관계를 파악하여 배포로 인한 영향인지 아닌지를 판단하는 작업은 상당한 경험과 시간이 필요합니다. 

이러한 문제를 해결하기 위해 카카오릴리즈는 Matrix AI와 연계하여 체인지 트래킹(Change Tracking) 기능을 개발했습니다. 체인지 트래킹은 배포 실행 후 24시간 동안 데이터 패턴을 분석하여 데이터 상태 변화를 실시간으로 감지하고 전반적인 상태를 판별하는 기능입니다.

![배포 직후 24시간 동안 자동으로 서비스 상태를 추적 및 판단하는 Change Tracking 화면]({{ site.baseurl }}/images/6054f488019900001.png)

이러한 체인지 트래킹 기능을 통해 개발자들은 배포 후에도 지속적인 모니터링 업무의 부담을 덜 수 있게 되었습니다.

카카오릴리즈가 그리는 미래는, 개발자가 코드를 푸시하는 그 순간부터 실제 사용자에게 안전하게 서비스가 제공되는 마지막 단계까지의 모든 과정을 AI와 시스템이 자동으로 처리하는 것입니다. 인간의 개입 없이도 신뢰할 수 있는 품질과 속도를 확보하는 E2E 자동화를 의미합니다.

실제로 하나의 메이저 배포가 이루어지기 위해서는 백엔드, 프론트엔드 등 여러 개의 서비스가 유기적으로 함께 움직여야 합니다. 예를 들어 웹 서비스를 배포한다고 했을 때, 단순히 백엔드 코드만 변경되는 것이 아니라 프론트엔드도 함께 수정되고 릴리즈되는 경우가 많습니다.

카카오릴리즈는 이러한 복잡한 배포 과정을 최대한 자동화하고자 합니다. 각 모듈에서 태그가 푸시되면 자동으로 배포 노트가 생성되고, AI가 이를 리뷰하여 문제가 없는지 검토합니다. 특히 주목할 점은, 이렇게 푸시된 여러 모듈의 변경사항들이 하나의 배포 노트로 통합된다는 점입니다. 

이를 통해 백엔드, 프론트엔드 등 다양한 구성 요소들의 변경 내역이 한눈에 정리되어, 배포와 관련된 모든 정보가 파편화되지 않고 일관되게 관리됩니다. 리뷰를 통과한 작업은 자동으로 배포되며, 배포 이후에는 모니터링 시스템이 실시간으로 서비스 상태를 감지합니다. 

만약 이상 징후가 감지된다면, AI는 원인을 분석하고 백엔드이든 프론트엔드이든 해당 모듈에 대해 롤백이 필요한지를 판단한 후, 필요한 조치를 즉시 수행합니다.

또한, 카카오릴리즈 플랫폼은 특정 배포(CD) 도구에 종속되지 않고, 향후에는 다양한 배포 도구들을 마치 플러그인처럼 유연하게 연동할 수 있도록 설계 방향을 잡고 있습니다. ArgoCD, Jenkins 등 각 조직의 기술 스택에 따라 선호하는 배포 도구를 자유롭게 붙일 수 있도록 하여, 다양한 팀과 프로젝트의 요구사항을 유연하게 수용할 수 있는 기반을 마련해가고 있습니다. 

이를 통해 각 팀은 자신들의 배포 환경을 유지하면서도, 카카오릴리즈가 제공하는 AI 기반 자동화의 혜택을 일관되게 누릴 수 있을 것입니다.

![배포 생명 주기의 각 단계별에서 일어나는 개발자와 AI 협업]({{ site.baseurl }}/images/37f9007b019900001.png)

-----

## 각주

1) 카카오릴리즈의 기본 작업 단위

2) 청크(Chunk)는 분리되어 있는 여러 정보 단위를 의미 있는 하나의 묶음으로 묶는 것을 말합니다.

3) 퓨샷 러닝(Few-shot Learning)은 아주 적은 수의(몇 개) 예시 데이터만을 가지고도 새로운 작업을 학습하거나 분류할 수 있는 머신러닝 방법입니다.
